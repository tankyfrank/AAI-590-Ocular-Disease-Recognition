{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gdown\n",
    "import zipfile\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = \"1oQ6Vy_HqZlVHnkFspgxMn0IcE__D8Kmh\"\n",
    "zip_filename = \"ocular-disease-recognition.zip\"\n",
    "extract_path = \"./ocular-disease-recognition\"\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(zip_filename):\n",
    "    print(f\"Downloading {zip_filename}...\")\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", zip_filename, quiet=False)\n",
    "else:\n",
    "    print(f\"{zip_filename} already exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if already extracted\n",
    "if not os.path.exists(extract_path):\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "    print(f\"Extracting {zip_filename}...\")\n",
    "\n",
    "    with zipfile.ZipFile(zip_filename, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_path)\n",
    "\n",
    "    print(f\"Extraction complete! Files extracted to: {extract_path}\")\n",
    "else:\n",
    "    print(f\"Extraction skipped: {extract_path} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (Update the path if necessary)\n",
    "dataset_path = \"processed_ocular_disease.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# **Split into Train, Validation, and Test Sets**\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)  # 70% Train, 30% Temp\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)  # 15% Val, 15% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class OcularDatasetGenerator(Sequence):\n",
    "    def __init__(self, df, batch_size=32, img_size=(128, 128), shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(df))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.df) / self.batch_size))  # Number of batches per epoch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = self.df.iloc[batch_indices]\n",
    "        X, y = self.__data_generation(batch)\n",
    "        return np.array(X), np.array(y)  # Return batch images and labels\n",
    "    \n",
    "    def __data_generation(self, batch):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for _, row in batch.iterrows():\n",
    "            left_image_path = os.path.join('ocular-disease-recognition/preprocessed_images', row['Left-Fundus'])\n",
    "            right_image_path = os.path.join('ocular-disease-recognition/preprocessed_images', row['Right-Fundus'])\n",
    "            \n",
    "            left_image = self.load_image(left_image_path)\n",
    "            right_image = self.load_image(right_image_path)\n",
    "\n",
    "            if left_image is None or right_image is None:\n",
    "                continue\n",
    "\n",
    "            combined_image = np.stack((left_image, right_image), axis=-1)  # Shape: (128, 128, 2)\n",
    "            X_batch.append(combined_image)\n",
    "\n",
    "            # Fix: Convert labels to integer type\n",
    "            y_batch.append(int(row['labels']))  \n",
    "\n",
    "        return np.array(X_batch, dtype=np.float32), np.array(y_batch, dtype=np.int32)\n",
    "\n",
    "\n",
    "    \n",
    "    def load_image(self, image_path):\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            return None\n",
    "        image = cv2.resize(image, self.img_size) / 255.0  # Normalize\n",
    "        return image\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# Create the generator\n",
    "batch_size = 32\n",
    "train_generator = OcularDatasetGenerator(df, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 8\n",
      "Epoch 1/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 145ms/step - accuracy: 0.4238 - loss: 1.6255 - val_accuracy: 0.4302 - val_loss: 1.5690\n",
      "Epoch 2/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - accuracy: 0.4649 - loss: 1.5134 - val_accuracy: 0.4319 - val_loss: 1.5002\n",
      "Epoch 3/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - accuracy: 0.4562 - loss: 1.4712 - val_accuracy: 0.4664 - val_loss: 1.4786\n",
      "Epoch 4/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - accuracy: 0.4763 - loss: 1.3895 - val_accuracy: 0.4625 - val_loss: 1.4522\n",
      "Epoch 5/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.4779 - loss: 1.3560 - val_accuracy: 0.4710 - val_loss: 1.3623\n",
      "Epoch 6/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.5083 - loss: 1.2800 - val_accuracy: 0.4954 - val_loss: 1.3640\n",
      "Epoch 7/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 138ms/step - accuracy: 0.5084 - loss: 1.2488 - val_accuracy: 0.4798 - val_loss: 1.3384\n",
      "Epoch 8/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - accuracy: 0.5357 - loss: 1.1855 - val_accuracy: 0.5075 - val_loss: 1.3097\n",
      "Epoch 9/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - accuracy: 0.5868 - loss: 1.0637 - val_accuracy: 0.5139 - val_loss: 1.2725\n",
      "Epoch 10/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - accuracy: 0.6126 - loss: 0.9828 - val_accuracy: 0.5504 - val_loss: 1.2761\n",
      "Epoch 11/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.6498 - loss: 0.8807 - val_accuracy: 0.5394 - val_loss: 1.3152\n",
      "Epoch 12/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 138ms/step - accuracy: 0.6913 - loss: 0.7866 - val_accuracy: 0.5504 - val_loss: 1.3485\n",
      "Epoch 13/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 138ms/step - accuracy: 0.7244 - loss: 0.6942 - val_accuracy: 0.5800 - val_loss: 1.3183\n",
      "Epoch 14/50\n",
      "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - accuracy: 0.7555 - loss: 0.6287 - val_accuracy: 0.5944 - val_loss: 1.4392\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# **Create Data Generators**\n",
    "batch_size = 32\n",
    "train_generator = OcularDatasetGenerator(train_df, batch_size=batch_size)\n",
    "val_generator = OcularDatasetGenerator(val_df, batch_size=batch_size)\n",
    "test_generator = OcularDatasetGenerator(test_df, batch_size=batch_size, shuffle=False)  # No shuffle for testing\n",
    "\n",
    "# **Get Number of Classes**\n",
    "num_classes = len(np.unique(df['labels']))\n",
    "print(f\"Number of Classes: {num_classes}\")\n",
    "\n",
    "# **Define CNN Model**\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 2)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')  # Using computed num_classes\n",
    "])\n",
    "\n",
    "# **Compile the model**\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# **Define Early Stopping Callback**\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',    # Stop if validation loss stops improving\n",
    "    patience=5,            # Wait for 5 epochs before stopping\n",
    "    restore_best_weights=True  # Restore best model weights\n",
    ")\n",
    "\n",
    "# **Train the Model with Early Stopping**\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=val_generator,  # Validation generator for early stopping\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.4794 - loss: 1.2924\n",
      "Test Accuracy: 0.4793\n"
     ]
    }
   ],
   "source": [
    "# **Evaluate the Model on Test Set**\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
